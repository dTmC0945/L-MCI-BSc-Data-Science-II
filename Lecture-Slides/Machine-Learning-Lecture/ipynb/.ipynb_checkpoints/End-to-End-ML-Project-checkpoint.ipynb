{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09ddb01-96ec-46b9-881e-7ace9e59cb86",
   "metadata": {},
   "source": [
    "Code for Machine Learning and Data Science II\n",
    "=============================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807bde7-696c-4372-b6b2-cb806daeb121",
   "metadata": {},
   "source": [
    "These are the code snippets used in End to End ML Project\n",
    "part of Machine Learning and Data Science II.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a201050-bc1e-4bad-82d6-a071acd88b07",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c51564-628f-4c76-b765-8ef7cb1419b5",
   "metadata": {},
   "source": [
    "#### Preamble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572842c-0c47-4157-8594-e454cea09a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ChalcedonPy as cp\n",
    "\n",
    "# Initialise ChalcedonPy\n",
    "cp.init(save_path=\"End-to-End-ML-Project\",\n",
    "        display_mode=\"slide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42e7d1-cf5c-4093-a6d3-b12d0a2c634d",
   "metadata": {},
   "source": [
    "#### Download Initial Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f915f99-d82e-4ef5-9f9c-3565678ebfea",
   "metadata": {},
   "source": [
    "First lets load the necessary modules for downloading the data so we\n",
    "can work on it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51dfa77d-eb8c-4972-a27c-e27b4f456a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd # for dataframes\n",
    "import tarfile # read/write tar files\n",
    "# to access and download data from web\n",
    "import urllib.request\n",
    "from tabulate import tabulate # for table printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab24d4-3c98-463f-99bf-a60d2535943d",
   "metadata": {},
   "source": [
    "Define a function called load<sub>housing</sub><sub>data</sub>() to access and\n",
    "download the data, finally returning a read of it using pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bc64a3-4f51-4020-9a5b-8b63868a8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data():\n",
    "    # path to save the file\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    # check if the path exists, if not create one\n",
    "\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/dTmC0945/L-MCI-BSc-Data-Science-II/raw/main/data/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7935d1-f02a-4937-b6c7-72042925ea55",
   "metadata": {},
   "source": [
    "Now read the data and assign it to the value housing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60df4167-7d6b-4b7a-83ac-43f63b30adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb321a-b4da-44dd-8f59-5e67aa73b0dc",
   "metadata": {},
   "source": [
    "Let's have a look at the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854d9470-cf84-48a0-8844-914b1f3f7390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aef187-9215-4b09-932e-da8ca7e7fea5",
   "metadata": {},
   "source": [
    "Each row represents one district.\n",
    "\n",
    "There are 10 attributes\n",
    "\n",
    "-   longitude,\n",
    "-   latitude,\n",
    "-   housing<sub>median</sub><sub>age</sub>,\n",
    "-   total<sub>rooms</sub>,\n",
    "-   total<sub>bed</sub> rooms,\n",
    "-   population,\n",
    "-   households,\n",
    "-   median<sub>income</sub>,\n",
    "-   median<sub>house</sub><sub>value</sub>,\n",
    "-   and ocean<sub>proximity</sub>.\n",
    "\n",
    "To get more information about the data use the info() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a445f72-cb19-4ef9-b761-934ecafe65c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(housing.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69afa7ac-4542-4e50-aaa9-7ceef2267a46",
   "metadata": {},
   "source": [
    "There seems to be some repetition on the ocean<sub>proximity</sub> parameters.\n",
    "Let's have a bit more look into the data.\n",
    "\n",
    "To get more information on it use the value<sub>counts</sub>() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344d439c-e893-4fd3-9114-2910b32fd6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: ocean_proximity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(housing[\"ocean_proximity\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012323dd-000e-43ab-9d0d-c30160461c60",
   "metadata": {},
   "source": [
    "Time to look at the the other fields using the describe() method which\n",
    "shows their numerical attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1527e44a-7bf7-4987-a0c4-611c9fc2c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of        longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                41.0        880.0           129.0   \n",
      "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2        -122.24     37.85                52.0       1467.0           190.0   \n",
      "3        -122.25     37.85                52.0       1274.0           235.0   \n",
      "4        -122.25     37.85                52.0       1627.0           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
      "20636    -121.21     39.49                18.0        697.0           150.0   \n",
      "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
      "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
      "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "0           322.0       126.0         8.3252            452600.0   \n",
      "1          2401.0      1138.0         8.3014            358500.0   \n",
      "2           496.0       177.0         7.2574            352100.0   \n",
      "3           558.0       219.0         5.6431            341300.0   \n",
      "4           565.0       259.0         3.8462            342200.0   \n",
      "...           ...         ...            ...                 ...   \n",
      "20635       845.0       330.0         1.5603             78100.0   \n",
      "20636       356.0       114.0         2.5568             77100.0   \n",
      "20637      1007.0       433.0         1.7000             92300.0   \n",
      "20638       741.0       349.0         1.8672             84700.0   \n",
      "20639      1387.0       530.0         2.3886             89400.0   \n",
      "\n",
      "      ocean_proximity  \n",
      "0            NEAR BAY  \n",
      "1            NEAR BAY  \n",
      "2            NEAR BAY  \n",
      "3            NEAR BAY  \n",
      "4            NEAR BAY  \n",
      "...               ...  \n",
      "20635          INLAND  \n",
      "20636          INLAND  \n",
      "20637          INLAND  \n",
      "20638          INLAND  \n",
      "20639          INLAND  \n",
      "\n",
      "[20640 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(housing.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712a87e-44d4-47a7-bf45-64e68496b59e",
   "metadata": {},
   "source": [
    "Allows the pretty print of the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387fb2e-62d6-4adc-b32b-dc04194905fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "housing.hist(bins=50,  figsize=(12, 8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84aba26-6038-4e9e-9ea7-9f1a1aaa7b70",
   "metadata": {},
   "source": [
    "#### Create a Set for Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcb7fe-560a-4024-bab0-f04361f808cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to shuffle and split data\n",
    "def shuffle_and_split_data(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7b878-6ee3-4c60-838d-c7150aba1687",
   "metadata": {},
   "source": [
    "To use the data we can do the following\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfab345-57ab-4271-8a8c-53cca85a11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = shuffle_and_split_data(housing, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7dfa9-d57e-48cb-9928-076d734a766d",
   "metadata": {},
   "source": [
    "Lets see the sizes of the datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d080038-8fcc-4c93-ae23-2404cb402cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of the training set is:\", len(train_set))\n",
    "print(\"The size of the test data is:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b2630-1f49-435c-993c-535814f5ece3",
   "metadata": {},
   "source": [
    "This will shuffle but because of shuffling the program will see\n",
    "all the data eventually which is not something good.\n",
    "\n",
    "To avoid it we set a RNG seed to keep the shuffled indices constant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285ac59-8b35-453f-b256-0d0937dbb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1ca98-7239-4f55-86d0-c851a280c36d",
   "metadata": {},
   "source": [
    "Here is another method in which we can keep the split constant even if\n",
    "the dataset is refreshed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7941262-bb4a-4edb-9b19-a72cfc128321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import crc32\n",
    "\n",
    "def is_id_in_test_set(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) < test_ratio * 2**32\n",
    "\n",
    "def split_data_with_id_hash(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(\n",
    "        lambda id_: is_id_in_test_set(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321d355-41b4-406d-b0b3-61b8bcf20dd8",
   "metadata": {},
   "source": [
    "Unfortunately, the housing dataset does not have an identifier column.\n",
    "The simplest solution is to use the row index as the ID:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30843266-7afe-4204-b530-76a31a108d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id = housing.reset_index()  # adds an `index` column\n",
    "train_set, test_set = split_data_with_id_hash(housing_with_id, 0.2, \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f92264-8f80-4f7c-8921-2dbdca85f9d8",
   "metadata": {},
   "source": [
    "If you use the row index as a unique identifier, you need to make\n",
    "sure that new data gets appended to the end of the dataset and that no row ever gets deleted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49b3ac-27d1-4b95-b9b5-6aa109bdefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
    "train_set, test_set = split_data_with_id_hash(housing_with_id, 0.2, \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a3dba-2156-48f0-8f01-cefa32ffa726",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a few functions to split datasets into multiple subsets in various ways.\n",
    "An easy function is train<sub>test</sub><sub>split</sub>()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33932c3-38e0-4089-bb2c-3bc9baff0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914ea35-1722-4d3d-a54f-eafb9482678e",
   "metadata": {},
   "source": [
    "To find the probability that a random sample of 1,000 people contains less than 48.5% female or\n",
    "more than 53.5% female when the population's female ratio is 51.1%, we use the binomial distribution.\n",
    "\n",
    "The cdf() method of the binomial distribution gives us the probability that the\n",
    "number of females will be equal or less than the given value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94577e1-3194-43e7-a1bf-003badfd4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "sample_size = 1000\n",
    "ratio_female = 0.511\n",
    "proba_too_small = binom(sample_size, ratio_female).cdf(485 - 1)\n",
    "proba_too_large = 1 - binom(sample_size, ratio_female).cdf(535)\n",
    "print(proba_too_small + proba_too_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989f5cb-00c3-41cc-9c06-62c21aa16f3d",
   "metadata": {},
   "source": [
    "However, for the ones who prefer numerical results over explicit solutions,\n",
    "there is also the below method to achieve a similar result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7b95e-8bc7-4deb-9b4c-2bcaa5dd1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "samples = (np.random.rand(100_000, sample_size) < ratio_female).sum(axis=1)\n",
    "((samples < 485) | (samples > 535)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bedbf-7bca-44ee-b0cb-3bf4d08ea757",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2462b4-0da8-4270-a382-798f9997a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Income category\")\n",
    "plt.ylabel(\"Number of districts\")\n",
    "housing[\"income_cat\"].value_counts().sort_index().plot.bar(rot=0, grid=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aecc3f-d478-4225-8299-65973d36e2a1",
   "metadata": {},
   "source": [
    "Now you are ready to do stratified sampling based on the income category.\n",
    "For this you can use Scikit-Learn’s StratifiedShuffleSplit class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ca3da-2a23-4b22-b7ec-b356f7f1f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "strat_splits = []\n",
    "for train_index, test_index in splitter.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set_n = housing.iloc[train_index]\n",
    "    strat_test_set_n = housing.iloc[test_index]\n",
    "    strat_splits.append([strat_train_set_n, strat_test_set_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355e4ad-9968-4970-9108-27e3c7f9b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set, strat_test_set = strat_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7878e-0c03-456e-9345-d0582f26020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set, strat_test_set = train_test_split(\n",
    "    housing,\n",
    "    test_size=0.2,\n",
    "    stratify=housing[\"income_cat\"],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ac8bd-a37a-43e2-80fe-cc7c24feca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543978b8-b7d3-4dae-9308-7f1e68326ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall %\": income_cat_proportions(housing),\n",
    "    \"Stratified %\": income_cat_proportions(strat_test_set),\n",
    "    \"Random %\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props.index.name = \"Income Category\"\n",
    "compare_props[\"Strat. Error %\"] = (compare_props[\"Stratified %\"] /\n",
    "                                   compare_props[\"Overall %\"] - 1)\n",
    "compare_props[\"Rand. Error %\"] = (compare_props[\"Random %\"] /\n",
    "                                  compare_props[\"Overall %\"] - 1)\n",
    "(compare_props * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cb0e1-9c0b-47f5-950d-af5b747429e6",
   "metadata": {},
   "source": [
    "Time to drop income<sub>cat</sub>() attribute to go back to the\n",
    "original state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c911d-3ca4-40ed-809e-51b3edda3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1504a-4b7e-4c6e-bca1-936c6e3fde38",
   "metadata": {},
   "source": [
    "### Discover and Visualize the Data to Gain Insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20829c-72a6-4506-b85d-59c50f81a811",
   "metadata": {},
   "source": [
    "Before we start playing with the data it is a good habit to\n",
    "create a copy so as to not tamper with the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864e03b-bec7-476b-801a-c9ea4c3d95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0eaaf3-bfd9-4a1a-974c-1694f8cddbad",
   "metadata": {},
   "source": [
    "#### Visualising Geographical Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1ffb3-8ece-4a71-8cc8-647335f14663",
   "metadata": {},
   "source": [
    "As data is a bunch of points in 2D space, it is benefical to\n",
    "plot it in a scatter plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08ffe4-4638-495f-80eb-f474f8e5d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind = \"scatter\",\n",
    "             x = \"longitude\",\n",
    "             y = \"latitude\",\n",
    "             title = \"Housing Market in California\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3aaa28-9309-484d-ad5b-6fa2435df4aa",
   "metadata": {},
   "source": [
    "This might remind you a state in a country but it is currently not\n",
    "possible to see a pattern.\n",
    "\n",
    "Let's set the alpha to 0.2 to see if it helps better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967e640-fc64-4e08-ad4a-ce7db40914c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind = \"scatter\",\n",
    "             x = \"longitude\",\n",
    "             y = \"latitude\",\n",
    "             title = r\"Housing Market in California ($\\alpha = 0.2$)\",\n",
    "             alpha = 0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e83f5-88da-4246-b383-9b0537c2853f",
   "metadata": {},
   "source": [
    "Let's make it a bit more interesting and create a plot where the higher cluster areas\n",
    "would be coloured red and sparser places will be coloured colder as the value of\n",
    "the land is less.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522c2f2-5712-43f9-a9b0-0e53d3515e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "             s=housing[\"population\"] / 100, label=\"population\",\n",
    "             c=\"median_house_value\", cmap=\"jet\", colorbar=True,\n",
    "             legend=True, sharex=False, figsize=(10, 7))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6829b5-7fcb-4a85-b283-7376b88dc7cc",
   "metadata": {},
   "source": [
    "Now we can see the housing prices are very much related to the location\n",
    "in this case closer to the ocean. To add a final addition let's superimpose\n",
    "the state map over it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a4828-828d-40b2-979c-c98b365f08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"california.png\"\n",
    "\n",
    "if not (IMAGES_PATH / filename).is_file():\n",
    "    homl3_root = \"https://github.com/ageron/handson-ml3/raw/main/\"\n",
    "    url = homl3_root + \"images/end_to_end_project/\" + filename\n",
    "    print(\"Downloading\", filename)\n",
    "    urllib.request.urlretrieve(url, IMAGES_PATH / filename)\n",
    "\n",
    "housing_renamed = housing.rename(columns={\n",
    "    \"latitude\": \"Latitude\", \"longitude\": \"Longitude\",\n",
    "    \"population\": \"Population\",\n",
    "    \"median_house_value\": \"Median house value (ᴜsᴅ)\"})\n",
    "\n",
    "plot_settings(style = \"slide\")\n",
    "housing_renamed.plot(\n",
    "             kind=\"scatter\", x=\"Longitude\", y=\"Latitude\",\n",
    "             s=housing_renamed[\"Population\"] / 100, label=\"Population\",\n",
    "             c=\"Median house value (ᴜsᴅ)\", cmap=\"jet\", colorbar=True,\n",
    "             legend=True, sharex=False, figsize=(10, 7))\n",
    "\n",
    "california_img = plt.imread(IMAGES_PATH / filename)\n",
    "axis = -124.55, -113.95, 32.45, 42.05\n",
    "plt.axis(axis)\n",
    "plt.imshow(california_img, extent=axis)\n",
    "\n",
    "store_fig(\"california-housing-prices-plot\",\n",
    "          style = \"slide\",\n",
    "          close = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5180c09-48e7-4a35-9669-e9c8c46d602a",
   "metadata": {},
   "source": [
    "#### Looking for Correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956b962-a15e-4275-8e87-0e8d8cd6380c",
   "metadata": {},
   "source": [
    "Time to see if there is any correlation between the value of the houses\n",
    "and other parameters using pearsons correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3260e-e134-46dd-b9f8-89d1489cb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(numeric_only=True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8643f6b-f88d-4c95-9b5f-a49f460c07e6",
   "metadata": {},
   "source": [
    "Another way to check for correlation between attributes is to\n",
    "use the pandas scatter<sub>matrix</sub>() function,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a4a20-842c-4ad9-ad80-c72dfd5f32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71614aa-ed9f-4c1b-acb6-f5d81c2214ba",
   "metadata": {},
   "source": [
    "The most promising attribute to predict the median house value\n",
    "is the median income,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c2696-29f6-40b0-b704-8f0b53ecf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90240c-d179-4c18-b61d-65403bc13bf2",
   "metadata": {},
   "source": [
    "#### Experimenting with Attribute Combinations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741331f-4897-4c83-80d6-a56349bdbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_house\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
    "housing[\"bedrooms_ratio\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
    "housing[\"people_per_house\"] = housing[\"population\"] / housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf72e63-3bfb-405d-8599-fc0ea463a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(numeric_only=True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709cab0-feee-4200-91d3-34ff500de3ed",
   "metadata": {},
   "source": [
    "### Prepare the Data for Machine Learning Algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7e023-142d-41a8-b853-89c4d55fd428",
   "metadata": {},
   "source": [
    "It’s time to prepare the data for your Machine Learning algorithms.\n",
    "Instead of doing this manually, you should write functions for this\n",
    "purpose, \n",
    "\n",
    "First revert to a clean training set and separate predictors and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5c576-d5ec-4f3a-bd91-fc51d31923d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be89a5-f458-4e2a-bd32-1f5e6f884b18",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea967d8-ac7d-4f58-8c49-d03736902082",
   "metadata": {},
   "source": [
    "Not all data comes perfect for ML as some of them may contain NaN or 0 or\n",
    "some other value which you don't want ML algorithm to process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d559d-1f63-4645-bb59-b98f015a2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows_idx = housing.isnull().any(axis=1)\n",
    "housing.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477ebc7-8a75-4ab7-b0c2-8483c9938add",
   "metadata": {},
   "source": [
    "Let's look at three (3) options:\n",
    "\n",
    "1 - Get rid of the corresponding districts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5031687-97e8-4675-a859-64e9d21fc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_option1 = housing.copy()\n",
    "housing_option1.dropna(subset=[\"total_bedrooms\"], inplace=True)  # option 1\n",
    "housing_option1.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546481f-e20f-4b4c-a4f0-a534025e8172",
   "metadata": {},
   "source": [
    "2 - Get rid of the whole attribute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8635e-531c-4504-8645-dee201547f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_option2 = housing.copy()\n",
    "housing_option2.drop(\"total_bedrooms\", axis=1, inplace=True)  # option 2\n",
    "housing_option2.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f072c4-4ed0-417c-a1a3-08fecef06e0a",
   "metadata": {},
   "source": [
    "3 - Set the values to some value (zero, the mean, the median, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee62839-7353-432e-b801-8050d4b3fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_option3 = housing.copy()\n",
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing_option3[\"total_bedrooms\"].fillna(median, inplace=True)  # option 3\n",
    "\n",
    "housing_option3.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e85ff-6f75-4f8a-a2c1-02a8931a93b1",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a handy class to take care of missing values: SimpleImputer.\n",
    "\n",
    "Separating out the numerical attributes to use the \"median\" strategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59219be-5b14-4ade-95e8-0d0b5f47844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4d7fc-d009-445f-8c34-d0ee67f0dbc0",
   "metadata": {},
   "source": [
    "create a copy of the data without the text attribute ocean<sub>proximity</sub>:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e026b51-750a-4edd-999a-014fd466b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca43fe-f340-40c7-b364-4489252cd429",
   "metadata": {},
   "source": [
    "can fit the imputer instance to the training data using the fit() method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8327d4e-d2f5-4c4b-b381-55a4bfe358f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2dfbf3-ed67-481d-8609-b783e9c2e5a7",
   "metadata": {},
   "source": [
    "we cannot be sure that there won’t be any missing values in new\n",
    "data after the system goes live, so it is safer to apply the\n",
    "imputer to all the numerical attributes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b638d41-d4b9-44ce-8790-9544c83c4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputer.statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104b66a-a005-4aa5-acc4-d9638443d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_num.median().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6e8e0-21a2-4e2f-b991-3f97038be8b4",
   "metadata": {},
   "source": [
    "use this “trained” imputer to transform the training set by\n",
    "replacing missing values with the learned medians:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede1193-54d3-4894-9173-52331abbaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "# to see the name of the columns\n",
    "print(imputer.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377c4b9-82b6-4709-835e-20e71f954bf0",
   "metadata": {},
   "source": [
    "To convert this to pd dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35926455-4039-4e3a-a05a-0c3a0a394dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c9605-b99a-48bf-9081-29a21fdb41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201fe39-4468-47db-989f-6af1b5cb1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0bd75-7d8d-49a7-a63f-83d0d5167fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)\n",
    "\n",
    "housing_tr.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34161f59-0cf7-4895-85b5-69b31747e2ba",
   "metadata": {},
   "source": [
    "Time to drop some outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1fbc6-61d9-4305-a7b5-a079fb4d222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isolation_forest = IsolationForest(random_state=42)\n",
    "outlier_pred = isolation_forest.fit_predict(X)\n",
    "\n",
    "print(outlier_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043eac3-4da5-430b-963b-4f317970d82b",
   "metadata": {},
   "source": [
    "#### Handling Text and Categorical Attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b4670-71da-493a-ad1d-0c45f2f6ae1e",
   "metadata": {},
   "source": [
    "Time to process text instead of numbers.\n",
    "\n",
    "In this dataset, there is just one: the ocean<sub>proximity</sub> attribute.\n",
    "Let’s look at its value for the first 10 instances:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382e678-9186-4d60-8b0a-5d1a0d3878bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e1ac4-3b25-4df3-96b2-0eb760c2ad15",
   "metadata": {},
   "source": [
    "As ML likes numbers instead of text, convert these values to numbers\n",
    "using OrdinalEncoder class from Scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e605ff-0f14-4c61-b945-643294f2c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5554519-18fe-4747-a7d0-2bf905ba7d7b",
   "metadata": {},
   "source": [
    "Let's see the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a577da-2ef3-4125-8e90-2409b08472c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_cat_encoded[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9dc90-95cc-4b31-b5b1-debe25bf09fd",
   "metadata": {},
   "source": [
    "And if we were to see the categories:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdaabb5-5f4b-435b-b56b-bcb017621255",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a4336-e0ed-4077-aa7c-8db3e21592a7",
   "metadata": {},
   "source": [
    "To stop from ML algorithm from treating the numbers too literally\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3cf15-d02e-4d2c-a81e-8d2a09590606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf833b-868d-4226-954d-a098aac5bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing_cat_1hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409726c-b8c4-4f90-8f83-a276c3fe9010",
   "metadata": {},
   "source": [
    "the output is a SciPy sparse matrix, instead of a NumPy array.\n",
    "\n",
    "convert it to a dense array if needed by calling the toarray() method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d076f8-19fe-42a4-8d14-337a638997bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_cat_1hot.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5974873-4982-4e5a-a887-7c9a711e850e",
   "metadata": {},
   "source": [
    "It is also possible to list categories using categoreis\\_ instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbbcae-249d-48c0-8ef8-c4384bba1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse_output=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "print(housing_cat_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb65ef9-8117-4bb9-af92-c5a2549f3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb09de-a5ef-4ca2-8e2c-f7cdc668f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({\"ocean_proximity\": [\"INLAND\", \"NEAR BAY\"]})\n",
    "pd.get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e33000-ce4c-4540-acbf-d4766a8cd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_encoder.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bd498-a402-461c-b428-ec61f3c2b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_unknown = pd.DataFrame({\"ocean_proximity\": [\"<2H OCEAN\", \"ISLAND\"]})\n",
    "pd.get_dummies(df_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5775f95-255e-45dd-8b2b-c40d12a9d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.handle_unknown = \"ignore\"\n",
    "print(cat_encoder.transform(df_test_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa57a8-97c8-4ded-931a-da5e0e30ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_encoder.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293314a-542f-46a3-adb9-4868a85fff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f01a5-f6d7-4a7a-a8c8-9ea5780580e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(cat_encoder.transform(df_test_unknown),\n",
    "                         columns=cat_encoder.get_feature_names_out(),\n",
    "                         index=df_test_unknown.index)\n",
    "\n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f97cc-0d9d-4c4f-af44-561a2d7f3a18",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800089c-62bd-4524-801e-2c2270d31b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "housing_num_min_max_scaled = min_max_scaler.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf51c3-6d72-4e09-8290-62689cb5bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "housing_num_std_scaled = std_scaler.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62804b-d0f8-47fd-a3ed-d7e9d562e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "housing[\"population\"].hist(ax=axs[0], bins=50)\n",
    "housing[\"population\"].apply(np.log).hist(ax=axs[1], bins=50)\n",
    "axs[0].set_xlabel(\"Population\")\n",
    "axs[1].set_xlabel(\"Log of population\")\n",
    "axs[0].set_ylabel(\"Number of districts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58a3e9-103d-46c4-9e5a-1e8cdd859ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [np.percentile(housing[\"median_income\"], p)\n",
    "               for p in range(1, 100)]\n",
    "flattened_median_income = pd.cut(housing[\"median_income\"],\n",
    "                                 bins=[-np.inf] + percentiles + [np.inf],\n",
    "                                 labels=range(1, 100 + 1))\n",
    "flattened_median_income.hist(bins=50)\n",
    "plt.xlabel(\"Median income percentile\")\n",
    "plt.ylabel(\"Number of districts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c6c63-4e48-48b0-9a1f-7a2182a3f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "age_simil_35 = rbf_kernel(housing[[\"housing_median_age\"]], [[35]], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df04895-d875-4f33-91de-d03e0e2cef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.linspace(housing[\"housing_median_age\"].min(),\n",
    "                   housing[\"housing_median_age\"].max(),\n",
    "                   500).reshape(-1, 1)\n",
    "gamma1 = 0.1\n",
    "gamma2 = 0.03\n",
    "rbf1 = rbf_kernel(ages, [[35]], gamma=gamma1)\n",
    "rbf2 = rbf_kernel(ages, [[35]], gamma=gamma2)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel(\"Housing median age\")\n",
    "ax1.set_ylabel(\"Number of districts\")\n",
    "ax1.hist(housing[\"housing_median_age\"], bins=50)\n",
    "\n",
    "ax2 = ax1.twinx()  # create a twin axis that shares the same x-axis\n",
    "color = \"#984ea3\"\n",
    "ax2.plot(ages, rbf1, color=color, label=\"gamma = 0.10\")\n",
    "ax2.plot(ages, rbf2, color=color, label=\"gamma = 0.03\", linestyle=\"--\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylabel(\"Age similarity\", color=color)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7af0e5-b6fd-4d99-acef-4dc37e137d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "scaled_labels = target_scaler.fit_transform(housing_labels.to_frame())\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(housing[[\"median_income\"]], scaled_labels)\n",
    "some_new_data = housing[[\"median_income\"]].iloc[:5]  # pretend this is new data\n",
    "\n",
    "scaled_predictions = model.predict(some_new_data)\n",
    "predictions = target_scaler.inverse_transform(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fc2b5-5fa6-4f92-ad08-0b920ec50083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f966b7-7d97-411f-a77e-3bae14958143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "model = TransformedTargetRegressor(LinearRegression(),\n",
    "                                   transformer=StandardScaler())\n",
    "model.fit(housing[[\"median_income\"]], housing_labels)\n",
    "predictions = model.predict(some_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864ccca-0ee9-4445-94a5-09b8d614fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f232151-d01a-4774-9251-04e8c03f180d",
   "metadata": {},
   "source": [
    "#### Custom Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e3a15-b90d-457b-81d6-4023269d955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log, inverse_func=np.exp)\n",
    "log_pop = log_transformer.transform(housing[[\"population\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816433a9-1c22-48a5-8b9a-f76687f2e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_transformer = FunctionTransformer(rbf_kernel,\n",
    "                                      kw_args=dict(Y=[[35.]], gamma=0.1))\n",
    "age_simil_35 = rbf_transformer.transform(housing[[\"housing_median_age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc7904-9cf7-4fa4-8f40-e41f409354e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(age_simil_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a269320-ccd2-4b39-9cc5-1bae514b83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_coords = 37.7749, -122.41\n",
    "sf_transformer = FunctionTransformer(rbf_kernel,\n",
    "                                     kw_args=dict(Y=[sf_coords], gamma=0.1))\n",
    "sf_simil = sf_transformer.transform(housing[[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b2462-473d-4dfd-96cd-18ee1e0c53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sf_simil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79f899-1f9e-445f-8376-d01d8a011a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_transformer = FunctionTransformer(lambda X: X[:, [0]] / X[:, [1]])\n",
    "print(ratio_transformer.transform(np.array([[1., 2.], [3., 4.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581967c-3da2-4791-946c-1cb1216640d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "class StandardScalerClone(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, with_mean=True):  # no *args or **kwargs!\n",
    "        self.with_mean = with_mean\n",
    "\n",
    "    def fit(self, X, y=None):  # y is required even though we don't use it\n",
    "        X = check_array(X)  # checks that X is an array with finite float values\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        self.scale_ = X.std(axis=0)\n",
    "        self.n_features_in_ = X.shape[1]  # every estimator stores this in fit()\n",
    "        return self  # always return self!\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)  # looks for learned attributes (with trailing _)\n",
    "        X = check_array(X)\n",
    "        assert self.n_features_in_ == X.shape[1]\n",
    "        if self.with_mean:\n",
    "            X = X - self.mean_\n",
    "        return X / self.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552071c-484b-4eb3-9756-804a1d956e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters, n_init=10,\n",
    "                              random_state=self.random_state)\n",
    "        self.kmeans_.fit(X, sample_weight=sample_weight)\n",
    "        return self  # always return self!\n",
    "\n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "    \n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return [f\"Cluster {i} similarity\" for i in range(self.n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f038bb3-5e28-4f6d-809f-ffd98f838bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1., random_state=42)\n",
    "similarities = cluster_simil.fit_transform(housing[[\"latitude\", \"longitude\"]],\n",
    "                                           sample_weight=housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6490997-b899-4668-8580-1ebfa17ed7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities[:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849563b-8faa-488b-963a-fb0cecaee3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_renamed = housing.rename(columns={\n",
    "    \"latitude\": \"Latitude\", \"longitude\": \"Longitude\",\n",
    "    \"population\": \"Population\",\n",
    "    \"median_house_value\": \"Median house value (ᴜsᴅ)\"})\n",
    "housing_renamed[\"Max cluster similarity\"] = similarities.max(axis=1)\n",
    "\n",
    "housing_renamed.plot(kind=\"scatter\", x=\"Longitude\", y=\"Latitude\", grid=True,\n",
    "                     s=housing_renamed[\"Population\"] / 100, label=\"Population\",\n",
    "                     c=\"Max cluster similarity\",\n",
    "                     cmap=\"jet\", colorbar=True,\n",
    "                     legend=True, sharex=False, figsize=(10, 7))\n",
    "plt.plot(cluster_simil.kmeans_.cluster_centers_[:, 1],\n",
    "         cluster_simil.kmeans_.cluster_centers_[:, 0],\n",
    "         linestyle=\"\", color=\"black\", marker=\"X\", markersize=20,\n",
    "         label=\"Cluster centers\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067475ef-fc90-4fb5-9aed-5027d9c9f199",
   "metadata": {},
   "source": [
    "#### Transformation Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1744aa-9080-45d9-a596-788bc6c11b4b",
   "metadata": {},
   "source": [
    "Now let's build a pipeline to preprocess the numerical attributes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7400d-2120-46a2-b131-188d3ad89bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbd78f-b5b1-451a-8b9f-455fd801f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4d8e7-55de-4abf-bfcd-e8e4d3a8adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "\n",
    "num_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00536211-5305-41d5-b474-bd715989b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_prepared = num_pipeline.fit_transform(housing_num)\n",
    "print(housing_num_prepared[:2].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04985d06-146f-4fe3-a8b3-8bba2e0d2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkey_patch_get_signature_names_out():\n",
    "    \"\"\"Monkey patch some classes which did not handle get_feature_names_out()\n",
    "       correctly in Scikit-Learn 1.0.*.\"\"\"\n",
    "    from inspect import Signature, signature, Parameter\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import make_pipeline, Pipeline\n",
    "    from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "    default_get_feature_names_out = StandardScaler.get_feature_names_out\n",
    "\n",
    "    if not hasattr(SimpleImputer, \"get_feature_names_out\"):\n",
    "      print(\"Monkey-patching SimpleImputer.get_feature_names_out()\")\n",
    "      SimpleImputer.get_feature_names_out = default_get_feature_names_out\n",
    "\n",
    "    if not hasattr(FunctionTransformer, \"get_feature_names_out\"):\n",
    "        print(\"Monkey-patching FunctionTransformer.get_feature_names_out()\")\n",
    "        orig_init = FunctionTransformer.__init__\n",
    "        orig_sig = signature(orig_init)\n",
    "\n",
    "        def __init__(*args, feature_names_out=None, **kwargs):\n",
    "            orig_sig.bind(*args, **kwargs)\n",
    "            orig_init(*args, **kwargs)\n",
    "            args[0].feature_names_out = feature_names_out\n",
    "\n",
    "        __init__.__signature__ = Signature(\n",
    "            list(signature(orig_init).parameters.values()) + [\n",
    "                Parameter(\"feature_names_out\", Parameter.KEYWORD_ONLY)])\n",
    "\n",
    "        def get_feature_names_out(self, names=None):\n",
    "            if callable(self.feature_names_out):\n",
    "                return self.feature_names_out(self, names)\n",
    "            assert self.feature_names_out == \"one-to-one\"\n",
    "            return default_get_feature_names_out(self, names)\n",
    "\n",
    "        FunctionTransformer.__init__ = __init__\n",
    "        FunctionTransformer.get_feature_names_out = get_feature_names_out\n",
    "\n",
    "monkey_patch_get_signature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b8b88-9c36-41f3-baa3-79488ed1a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_num_prepared = pd.DataFrame(\n",
    "    housing_num_prepared, columns=num_pipeline.get_feature_names_out(),\n",
    "    index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e175a94-5299-445a-9976-1d9efb9c1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_num_prepared.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382feb8-2aa7-46d8-92f6-a1e4c8cc922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_pipeline.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac244b34-2588-49d2-80cd-8f6c8d9f7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd4313-655c-48e9-8e17-e7d839f56382",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73e775-8fa2-4995-a9b8-c7e971102482",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline.named_steps[\"simpleimputer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a399d-02de-4ced-ac17-f807a8d0f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline.set_params(simpleimputer__strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf56adc-409f-4341-a499-8a68dc62635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\",\n",
    "               \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e298ee-9ce7-472a-8aa5-f52b8bf68033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (cat_pipeline, make_column_selector(dtype_include=object)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c70d3-91b0-4c74-8950-a083dd7c66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = preprocessing.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b280062-a710-43fa-be9d-7591221653fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_fr = pd.DataFrame(\n",
    "    housing_prepared,\n",
    "    columns=preprocessing.get_feature_names_out(),\n",
    "    index=housing.index)\n",
    "housing_prepared_fr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2aa392-4de1-4840-a78a-2baa38d24924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_ratio(X):\n",
    "    return X[:, [0]] / X[:, [1]]\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return [\"ratio\"]  # feature names out\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(column_ratio, feature_names_out=ratio_name),\n",
    "        StandardScaler())\n",
    "\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n",
    "    StandardScaler())\n",
    "cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1., random_state=42)\n",
    "default_num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                                     StandardScaler())\n",
    "preprocessing = ColumnTransformer([\n",
    "        (\"bedrooms\", ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n",
    "        (\"rooms_per_house\", ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
    "        (\"people_per_house\", ratio_pipeline(), [\"population\", \"households\"]),\n",
    "        (\"log\", log_pipeline, [\"total_bedrooms\", \"total_rooms\", \"population\",\n",
    "                               \"households\", \"median_income\"]),\n",
    "        (\"geo\", cluster_simil, [\"latitude\", \"longitude\"]),\n",
    "        (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "    ],\n",
    "    remainder=default_num_pipeline)  # one column remaining: housing_median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb66e19-1c22-4a9e-8617-f29f78bdc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = preprocessing.fit_transform(housing)\n",
    "print(housing_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32482f88-40f9-4a2d-b103-392a0d11a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocessing.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6db9de-ccee-443c-8bb5-07dbbd547a38",
   "metadata": {},
   "source": [
    "### Select and Train a Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b0075-8252-4707-92fc-e64a979d1bef",
   "metadata": {},
   "source": [
    "#### Training and Evaluating on the Training Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc52557-7d68-4f98-a1ca-9e85b570a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = make_pipeline(preprocessing, LinearRegression())\n",
    "print(lin_reg.fit(housing, housing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc833c-4fde-4e6a-9023-01afe0e43cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = lin_reg.predict(housing)\n",
    "print(housing_predictions[:5].round(-2))  # -2 = rounded to the nearest hundred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c88f2-f2cc-4106-bb07-0490673fb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_labels.iloc[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b93942-9a0e-484a-a4fe-f24ba4731e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ratios = housing_predictions[:5].round(-2) / housing_labels.iloc[:5].values - 1\n",
    "print(\", \".join([f\"{100 * ratio:.1f}%\" for ratio in error_ratios]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8aa10-b882-4303-bec7-01c2291953e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_rmse = mean_squared_error(housing_labels, housing_predictions,\n",
    "                              squared=False)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c41cfa-962e-4a12-9c09-f5e2c61fa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = make_pipeline(preprocessing, DecisionTreeRegressor(random_state=42))\n",
    "tree_reg.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57858028-d778-4785-b7ef-779178859725",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(housing)\n",
    "tree_rmse = mean_squared_error(housing_labels, housing_predictions,\n",
    "                              squared=False)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc17b3a-46cd-4b91-8be4-a510058f0b92",
   "metadata": {},
   "source": [
    "#### Better Evaluation using Cross-Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6efa5a-2117-43e5-9575-d569ae080fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_rmses = -cross_val_score(tree_reg, housing, housing_labels,\n",
    "                              scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786c64c-ab64-42e6-81b0-daa80d8f653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(tree_rmses).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5e478-7b85-4e9f-9c09-13e9bf7eec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_rmses = -cross_val_score(lin_reg, housing, housing_labels,\n",
    "                              scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "pd.Series(lin_rmses).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad4d26-08fb-4ffc-9a53-d65acd4afbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = make_pipeline(preprocessing,\n",
    "                           RandomForestRegressor(random_state=42))\n",
    "forest_rmses = -cross_val_score(forest_reg, housing, housing_labels,\n",
    "                                scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c198a-6ed0-4898-8242-ef9ba889481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(forest_rmses).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a009b8-7684-4214-bb33-ce4320164df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg.fit(housing, housing_labels)\n",
    "housing_predictions = forest_reg.predict(housing)\n",
    "forest_rmse = mean_squared_error(housing_labels, housing_predictions,\n",
    "                                 squared=False)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c105a-3d6c-4e0f-84a1-0b5d11ac9d2a",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dcf159-453d-465e-be00-3265b734bd50",
   "metadata": {},
   "source": [
    "#### Using Grid Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a3de3-0979-4986-9d55-d2622216c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestRegressor(random_state=42)),\n",
    "])\n",
    "param_grid = [\n",
    "    {'preprocessing__geo__n_clusters': [5, 8, 10],\n",
    "     'random_forest__max_features': [4, 6, 8]},\n",
    "    {'preprocessing__geo__n_clusters': [10, 15],\n",
    "     'random_forest__max_features': [6, 8, 10]},\n",
    "]\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=3,\n",
    "                           scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5bf3b-a3db-4e48-b2b5-e3a16ecaadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(full_pipeline.get_params().keys())[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38543cc7-f06d-497b-8d2e-31c36d35e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2795fed-0b7c-4121-aa56-fd911614fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c074-d555-443f-9104-abd31b380d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "# extra code – these few lines of code just make the DataFrame look nicer\n",
    "cv_res = cv_res[[\"param_preprocessing__geo__n_clusters\",\n",
    "                 \"param_random_forest__max_features\", \"split0_test_score\",\n",
    "                 \"split1_test_score\", \"split2_test_score\", \"mean_test_score\"]]\n",
    "score_cols = [\"split0\", \"split1\", \"split2\", \"mean_test_rmse\"]\n",
    "cv_res.columns = [\"n_clusters\", \"max_features\"] + score_cols\n",
    "cv_res[score_cols] = -cv_res[score_cols].round().astype(np.int64)\n",
    "\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162278b-78a1-49d0-8429-42094c839748",
   "metadata": {},
   "source": [
    "#### Randomised Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c8499-47d6-428f-89ac-eb0a50c72a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b04a70-c9c1-4042-9e7c-64f8a7d3a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'preprocessing__geo__n_clusters': randint(low=3, high=50),\n",
    "                  'random_forest__max_features': randint(low=2, high=20)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(\n",
    "    full_pipeline, param_distributions=param_distribs, n_iter=10, cv=3,\n",
    "    scoring='neg_root_mean_squared_error', random_state=42)\n",
    "\n",
    "rnd_search.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab70b6-ef41-485b-a7e2-c7e3a3668087",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(rnd_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res = cv_res[[\"param_preprocessing__geo__n_clusters\",\n",
    "                 \"param_random_forest__max_features\", \"split0_test_score\",\n",
    "                 \"split1_test_score\", \"split2_test_score\", \"mean_test_score\"]]\n",
    "cv_res.columns = [\"n_clusters\", \"max_features\"] + score_cols\n",
    "cv_res[score_cols] = -cv_res[score_cols].round().astype(np.int64)\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b00b41-5d0f-4d66-a5a0-ea2277425b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform, geom, expon\n",
    "\n",
    "xs1 = np.arange(0, 7 + 1)\n",
    "randint_distrib = randint(0, 7 + 1).pmf(xs1)\n",
    "\n",
    "xs2 = np.linspace(0, 7, 500)\n",
    "uniform_distrib = uniform(0, 7).pdf(xs2)\n",
    "\n",
    "xs3 = np.arange(0, 7 + 1)\n",
    "geom_distrib = geom(0.5).pmf(xs3)\n",
    "\n",
    "xs4 = np.linspace(0, 7, 500)\n",
    "expon_distrib = expon(scale=1).pdf(xs4)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(xs1, randint_distrib, label=\"scipy.randint(0, 7 + 1)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.axis([-1, 8, 0, 0.2])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.fill_between(xs2, uniform_distrib, label=\"scipy.uniform(0, 7)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.legend()\n",
    "plt.axis([-1, 8, 0, 0.2])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(xs3, geom_distrib, label=\"scipy.geom(0.5)\")\n",
    "plt.xlabel(\"Hyperparameter value\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.axis([0, 7, 0, 1])\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.fill_between(xs4, expon_distrib, label=\"scipy.expon(scale=1)\")\n",
    "plt.xlabel(\"Hyperparameter value\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.legend()\n",
    "plt.axis([0, 7, 0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6393d-6663-42f3-a186-d36ca85d3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "xs1 = np.linspace(0, 7, 500)\n",
    "expon_distrib = expon(scale=1).pdf(xs1)\n",
    "\n",
    "log_xs2 = np.linspace(-5, 3, 500)\n",
    "log_expon_distrib = np.exp(log_xs2 - np.exp(log_xs2))\n",
    "\n",
    "xs3 = np.linspace(0.001, 1000, 500)\n",
    "loguniform_distrib = loguniform(0.001, 1000).pdf(xs3)\n",
    "\n",
    "log_xs4 = np.linspace(np.log(0.001), np.log(1000), 500)\n",
    "log_loguniform_distrib = uniform(np.log(0.001), np.log(1000)).pdf(log_xs4)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.fill_between(xs1, expon_distrib,\n",
    "                 label=\"scipy.expon(scale=1)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.legend()\n",
    "plt.axis([0, 7, 0, 1])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.fill_between(log_xs2, log_expon_distrib,\n",
    "                 label=\"log(X) with X ~ expon\")\n",
    "plt.legend()\n",
    "plt.axis([-5, 3, 0, 1])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.fill_between(xs3, loguniform_distrib,\n",
    "                 label=\"scipy.loguniform(0.001, 1000)\")\n",
    "plt.xlabel(\"Hyperparameter value\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.legend()\n",
    "plt.axis([0.001, 1000, 0, 0.005])\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.fill_between(log_xs4, log_loguniform_distrib,\n",
    "                 label=\"log(X) with X ~ loguniform\")\n",
    "plt.xlabel(\"Log of hyperparameter value\")\n",
    "plt.legend()\n",
    "plt.axis([-8, 1, 0, 0.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d29386-6722-4a79-a803-5259dbacbbe3",
   "metadata": {},
   "source": [
    "#### Analyse the Best Models and Errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1a138-0e7b-4e6d-bc9c-e062eb4ca362",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = rnd_search.best_estimator_  # includes preprocessing\n",
    "feature_importances = final_model[\"random_forest\"].feature_importances_\n",
    "print(feature_importances.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f41b49-acda-4e6a-ac3d-100bf87fe9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances,\n",
    "           final_model[\"preprocessing\"].get_feature_names_out()),\n",
    "           reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc711a-5ce7-4a25-845a-2a7807a3e07c",
   "metadata": {},
   "source": [
    "\n",
    "| 0.19087378222226137|log_<sub>median</sub><sub>income</sub>|\n",
    "| 0.07625632853052883|cat_<sub>ocean</sub><sub>proximity</sub><sub>INLAND</sub>|\n",
    "| 0.06365028932207333|bedrooms_<sub>ratio</sub>|\n",
    "| 0.057834740538722625|rooms<sub>per</sub><sub>house</sub>_<sub>ratio</sub>|\n",
    "| 0.04907003277818634|people<sub>per</sub><sub>house</sub>_<sub>ratio</sub>|\n",
    "| 0.038165489600129165|geo_<sub>Cluster</sub> 3 similarity|\n",
    "| 0.025700861301416925|geo_<sub>Cluster</sub> 22 similarity|\n",
    "| 0.02186407550147744|geo_<sub>Cluster</sub> 17 similarity|\n",
    "| 0.021818299311019237|geo_<sub>Cluster</sub> 6 similarity|\n",
    "| 0.018249904787654904|geo_<sub>Cluster</sub> 2 similarity|\n",
    "| 0.017263517651784216|geo_<sub>Cluster</sub> 32 similarity|\n",
    "| 0.015649725317935348|geo_<sub>Cluster</sub> 18 similarity|\n",
    "| 0.015236556682888558|geo_<sub>Cluster</sub> 40 similarity|\n",
    "| 0.014160249342841777|geo_<sub>Cluster</sub> 43 similarity|\n",
    "| 0.014113856232349186|geo_<sub>Cluster</sub> 7 similarity|\n",
    "| 0.013968406769681294|geo_<sub>Cluster</sub> 21 similarity|\n",
    "| 0.013781633271007265|geo_<sub>Cluster</sub> 38 similarity|\n",
    "| 0.013515022744382842|geo_<sub>Cluster</sub> 34 similarity|\n",
    "| 0.013508738042902313|geo_<sub>Cluster</sub> 41 similarity|\n",
    "| 0.012844820424121687|geo_<sub>Cluster</sub> 24 similarity|\n",
    "| 0.01236427981858226|geo_<sub>Cluster</sub> 10 similarity|\n",
    "| 0.01176408158393247|remainder_<sub>housing</sub><sub>median</sub><sub>age</sub>|\n",
    "| 0.011436849025886087|geo_<sub>Cluster</sub> 31 similarity|\n",
    "| 0.011430032718708965|geo_<sub>Cluster</sub> 30 similarity|\n",
    "| 0.011262888671999243|geo_<sub>Cluster</sub> 42 similarity|\n",
    "| 0.011082126500672662|geo_<sub>Cluster</sub> 16 similarity|\n",
    "| 0.01087991522984511|geo_<sub>Cluster</sub> 1 similarity|\n",
    "| 0.0106352262787596|geo_<sub>Cluster</sub> 25 similarity|\n",
    "| 0.010629636976156976|geo_<sub>Cluster</sub> 26 similarity|\n",
    "| 0.010325438106958176|geo_<sub>Cluster</sub> 20 similarity|\n",
    "| 0.009978597341631139|geo_<sub>Cluster</sub> 35 similarity|\n",
    "| 0.009811902116084414|geo_<sub>Cluster</sub> 14 similarity|\n",
    "| 0.00926835411026417|geo_<sub>Cluster</sub> 39 similarity|\n",
    "| 0.009210910491673824|geo_<sub>Cluster</sub> 37 similarity|\n",
    "| 0.008838219938405523|geo_<sub>Cluster</sub> 0 similarity|\n",
    "| 0.00883623406533351|geo_<sub>Cluster</sub> 9 similarity|\n",
    "| 0.008743931217845727|geo_<sub>Cluster</sub> 8 similarity|\n",
    "| 0.008563362393325231|geo_<sub>Cluster</sub> 36 similarity|\n",
    "| 0.008465719960196051|geo_<sub>Cluster</sub> 28 similarity|\n",
    "| 0.008001576292023282|geo_<sub>Cluster</sub> 44 similarity|\n",
    "| 0.007942690751495287|geo_<sub>Cluster</sub> 4 similarity|\n",
    "| 0.00792848112158647|geo_<sub>Cluster</sub> 11 similarity|\n",
    "| 0.007724755678419276|log_<sub>total</sub><sub>rooms</sub>|\n",
    "| 0.0071161520040372486|log_<sub>population</sub>|\n",
    "| 0.006792638958967365|log_<sub>total</sub><sub>bedrooms</sub>|\n",
    "| 0.006504955481581277|log_<sub>households</sub>|\n",
    "| 0.006215189140929538|geo_<sub>Cluster</sub> 23 similarity|\n",
    "| 0.0056299034599644185|geo_<sub>Cluster</sub> 19 similarity|\n",
    "| 0.005544728303210014|geo_<sub>Cluster</sub> 27 similarity|\n",
    "| 0.00526201040506395|geo_<sub>Cluster</sub> 33 similarity|\n",
    "| 0.004834036365364593|geo_<sub>Cluster</sub> 15 similarity|\n",
    "| 0.004177160622478634|geo_<sub>Cluster</sub> 12 similarity|\n",
    "| 0.0040378619656822245|geo_<sub>Cluster</sub> 13 similarity|\n",
    "| 0.0036513301086410445|geo_<sub>Cluster</sub> 29 similarity|\n",
    "| 0.0033595680753400604|cat_<sub>ocean</sub><sub>proximity</sub>_&lt;1H OCEAN|\n",
    "| 0.001969988014822343|geo_<sub>Cluster</sub> 5 similarity|\n",
    "| 0.001955486511135513|cat_<sub>ocean</sub><sub>proximity</sub><sub>NEAR</sub> OCEAN|\n",
    "| 0.0002362031046240973|cat_<sub>ocean</sub><sub>proximity</sub><sub>NEAR</sub> BAY|\n",
    "| 6.124671500751693e-05|cat_<sub>ocean</sub><sub>proximity</sub><sub>ISLAND</sub>|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ca333-5ace-4b7b-935e-0f2824e04a71",
   "metadata": {},
   "source": [
    "#### Evaluate using the Test Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa25f5-a166-4d97-a169-724db63fa18f",
   "metadata": {},
   "source": [
    "Time to evaluate the model with the test set:\n",
    "\n",
    "1.  get the predictors and the labels from the test set,\n",
    "2.  run final<sub>mode</sub> to transform data,\n",
    "3.  make predictions,\n",
    "4.  evaluate the predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f291023-2da8-4413-b0fd-a4f319aa7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "final_rmse = mean_squared_error(y_test, final_predictions, squared=False)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a089a-3c5b-4be8-a8c1-21a5fb729c1e",
   "metadata": {},
   "source": [
    "We need to know How good is the model. For this, compute\n",
    "the %95 [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval) for the generalisation error using\n",
    "scipy.stats.t.interval().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b831bad-dbd3-485f-ada2-4c60c1365913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "result= np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6543d7d2-e7e1-4566-92f7-7a5e87f89781",
   "metadata": {},
   "source": [
    "The value is roughly in the middle of it.\n",
    "\n",
    "There are different ways of calculating it as well.\n",
    "\n",
    "Below is the manual way of writing the confidence interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6691159-a1e0-488d-88d9-2512c98ac83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(squared_errors)\n",
    "mean = squared_errors.mean()\n",
    "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
    "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "print(np.sqrt(mean - tmargin), np.sqrt(mean + tmargin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c413639-1623-493b-85ea-84c8212e4f87",
   "metadata": {},
   "source": [
    "Alternatively, we can use z-score (i.e., [Standard score](https://en.wikipedia.org/wiki/Standard_score)) to calculate as the\n",
    "data set is relatively big.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff0745-66b5-416e-a9d3-506e58854d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "print(np.sqrt(mean - zmargin), np.sqrt(mean + zmargin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c46be-5d23-4e07-bf32-a2d1659bf0d0",
   "metadata": {},
   "source": [
    "NOTE: Doing a lot of hyperparameter tuning can make the model behave worse as\n",
    "it would be highly tuned to the train data and may not be as performant as on test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb2060-961c-4098-94a5-2c66cc3b6ed9",
   "metadata": {},
   "source": [
    "#### Saving the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b21863-50ee-43da-8f99-9c47aaa3bbcb",
   "metadata": {},
   "source": [
    "Time to get the model into production and the easiest way to do is to save the best model.\n",
    "\n",
    "To save it, you can use the joblib module [[More Info]​](https://joblib.readthedocs.io/en/stable/), which allows pipelining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f2311-6452-4c28-b1e4-79bf192757c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(final_model, \"my_california_housing_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1164be-b3dd-4234-a344-0e12d84c38a4",
   "metadata": {},
   "source": [
    "Once saved, you can load and use it, with all the necessary dependencies loaded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074cb001-a603-48c1-af2e-80d44131be93",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my_california_housing_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c2/_hry6n9d5v1527pv4f_gfjxm0000gn/T/ipykernel_76668/3010287116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#    [...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfinal_model_reloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_california_housing_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pretend these are new districts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_california_housing_model.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# extra code – excluded for conciseness\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def column_ratio(X):\n",
    "    return X[:, [0]] / X[:, [1]]\n",
    "\n",
    "#class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "#    [...]\n",
    "\n",
    "final_model_reloaded = joblib.load(\"my_california_housing_model.pkl\")\n",
    "\n",
    "new_data = housing.iloc[:5]  # pretend these are new districts\n",
    "predictions = final_model_reloaded.predict(new_data)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
